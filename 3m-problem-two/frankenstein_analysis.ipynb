{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(textfile,n):\n",
    "    from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "    from nltk.corpus import stopwords\n",
    "    from collections import Counter\n",
    "    from pandas import DataFrame\n",
    "    \n",
    "    # Open file into variable, read contents and convert to lowercase, close file\n",
    "    f=open(textfile)\n",
    "    filecontents=f.read().lower()\n",
    "    f.close()\n",
    "    \n",
    "    # Tokenize by lowercase words only, no numbers or non-alphabetic characters like punctuation\n",
    "    tokenizer=nltk.RegexpTokenizer('[a-z]\\w+')\n",
    "    word_processed=tokenizer.tokenize(filecontents)\n",
    "    \n",
    "    # Using NLTK pre-built stopwords list containing most common english stop words like \"the\", \"an\", \"a\", etc. which are not useful for this analysis\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    \n",
    "    # If words in the text are not in the list of stop words then only include those words in the list of meaningful words, going word by word through the entire text\n",
    "    words_filtered=[word for word in word_processed if word not in stop_words]\n",
    "    \n",
    "    # Build a set based on the filtered words list above so that we can know which meaningful words are in the text and separate that feature from frequency of the words occuring in the text\n",
    "    unique_words=set(words_filtered)\n",
    "\n",
    "    # Use counter function to create a dictionary of each word in the filtered list and the count of the number of times those words appeared in the text\n",
    "    count=Counter(words_filtered)\n",
    "    out=count.most_common(n)\n",
    "    text_length=len(words_filtered) # only meaningful words needed for frequency analysis\n",
    "        \n",
    "    # Calculate percentage that the most common words occur among the entire text after the text has been processed to remove stop words, numbers, and punctuation in order to only include meaningful words in the analysis\n",
    "    freq=[]\n",
    "    i=0\n",
    "    while i<n:\n",
    "        calc=100 * (out[i][1]) / text_length\n",
    "        out[i]=out[i] + (str(round(calc,2)),)\n",
    "        i+=1    \n",
    "\n",
    "    # Output neat table of results\n",
    "    df=DataFrame(out,columns=['Word','Count','Percentage of text (%)'],index=[list(range(1,n+1))])\n",
    "    \n",
    "    return {'df':df, \"unique words\":unique_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57543a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return (1) count of most common words and (2) breakdown of part of speech tags for unique words in the processed set of words from the text (which includes only meaningful words)\n",
    "from nltk import pos_tag, ne_chunk\n",
    "\n",
    "output=most_common(\"84-0.txt\",5)\n",
    "print(f'{output.get(\"df\")}')\n",
    "\n",
    "unique_words=output.get(\"unique words\")\n",
    "pos_tag(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13341c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
